
<!doctype html>
<html>
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

        <title>end to end image quality assessment using deep neuarl networks</title>

        <link rel="stylesheet" href="https://cdn.bootcss.com/reveal.js/3.4.1/css/reveal.min.css">
        
        <!-- theme -->
        <script>
            var link = document.createElement( 'link' );
            link.rel = 'stylesheet';
            link.type = 'text/css';
            var theme ='black';
            switch (theme){
                case 'black':
                    link.href = 'https://cdn.bootcss.com/reveal.js/3.4.1/css/theme/black.min.css';
                    break;
                case 'beige':
                    link.href = 'https://cdn.bootcss.com/reveal.js/3.4.1/css/theme/beige.min.css';
                    break;
                case 'blood':
                    link.href = 'https://cdn.bootcss.com/reveal.js/3.4.1/css/theme/blood.min.css';
                    break;
                case 'league':
                    link.href = 'https://cdn.bootcss.com/reveal.js/3.4.1/css/theme/league.min.css';
                    break;
                case 'moon':
                    link.href = 'https://cdn.bootcss.com/reveal.js/3.4.1/css/theme/moon.min.css';
                    break;
                case 'night':
                    link.href = 'https://cdn.bootcss.com/reveal.js/3.4.1/css/theme/night.min.css';
                    break;
                case 'serif':
                    link.href = 'https://cdn.bootcss.com/reveal.js/3.4.1/css/theme/serif.min.css';
                    break;
                case 'sky':
                    link.href = 'https://cdn.bootcss.com/reveal.js/3.4.1/css/theme/sky.min.css';
                    break;
                case 'solarized':
                    link.href = 'https://cdn.bootcss.com/reveal.js/3.4.1/css/theme/solarized.min.css';
                    break;
                case 'white':
                    link.href = 'https://cdn.bootcss.com/reveal.js/3.4.1/css/theme/white.min.css';
                    break;
                default:
            }
            
            document.getElementsByTagName( 'head' )[0].appendChild( link );
        </script>
        <!-- Theme used for syntax highlighting of code -->
        <link rel="stylesheet" href="https://cdn.bootcss.com/reveal.js/3.4.1/lib/css/zenburn.min.css">
        <link href="https://cdn.bootcss.com/reveal.js/3.4.1/css/print/paper.min.css" rel="stylesheet">
        <!-- Printing and PDF exports -->
        
    </head>
    <body>
        <div class="reveal">
            <div class="slides">
                <section data-markdown
                         data-separator="^\n---\n"
                         data-separator-vertical="^\n--\n"
                         data-separator-notes="^Note:">
                    <script type="text/template">end to end image quality assessment using deep neuarl networks





## ABSTRCT

1. we propose MEON.
2. MEON consists of ...
3. unlike traditional way 
4. different from
5. achieves state of the art 



## Introduction

1. BIQA aims to ...[1] .not be resolved[2]. (BIQA motivation)
2. Early ,handcrafted features[3-6],rely on HVS[7-8].prediction function built upon feature representation.feature extraction and quality prediction stages are designed separately.(Early method's problems)
3. with development of ... ,... becomes possible.(now can solve the problems)





1. DNN has shown great promises in many vision tasks,but BIQA is challenging due to lack of samples for training  (the problems about DNN in BIQA)

2. Note that largest database in  BIQA contains only 3000 annotations,while digital images live in a space of millions of dimensions.(introduce above problems)

3. previous DNN-based BIQA methods tackle this challenge in three ways.first ,pre-trained,

   second,assign all patches a MOS .three limitations,score of patches with out context is not well defined .local image quality within context varies across spatial locations .pathes with similar statistical behaviors may have substantially different quality. (how solve this problem in previous way)

   third,make use of full-reference IQA models for quality annotation. their performances is directly affected by...

   Other methods for generating training data involve the creation of synthetic scores and disciminable image pairs,both of which rely on ..suffer from...






1. In this work, we describe a framework for ...BIQA based on ...,Motivated by previous works[16 24],we ....

2. on the one hand, ...because, on the other hand ,.... as shown in fig .1.  shared features at early layers.

   feature sharing not only ... ,but also  

   enables the network to pre-train the shared layers via subtask I,for which large-scale training data can be automatically generated at low cost.

3. unlike traditional multi-task learning..., as show in .as such ,...for better prediciton

4. we defined a layer ...to guarantee the feasibility of backpropagation.

5. after pre-trained,the entire network is end to end optimized using a variant of the stochastic gradient method.

6. In addition,instead of using rectified linear unit ,we adopt generalized divisive normalization joint nonlineartity as the activation function that .....(good)[26-28] we empirically show that ...

7. we evaluate the resulting on ...,demonstrate that it achieves....


## RELATED WORK

In this section,we provide a brief review of...and previous studies closely related to our work.

1. early BIQA research focused on extracting distortion-specific features that can handle only one distortion type .such as 
2. ...features are popular .
3. 

s



## MEON FOR BIQA 

1.  we take a raw image of 256 256 3 as input .

2. MEON consists of ..

3. I aims to ,II whose goal is to .each subtask involves a loss function. 

4. pre-trained the shared layers in MEON via Subtask I and then jointly optimize the entire network with unified loss function .(how loss train)

5. In this section, we first describe GDN as our nonlinear activation function used in MEON and then present in detail the construction of the two subtasks in Fig. 3. Finally,we introduce our end to end training and testing procedures.

   







## Results

1. Images produced by the traditional pipeline in extreme low-light conditions suffer from severe noise and color distortion.
</script>
                </section>
            </div>
        </div>

        <script src="https://cdn.bootcss.com/reveal.js/3.4.1/lib/js/head.min.js"></script>
        <script src="https://cdn.bootcss.com/reveal.js/3.4.1/js/reveal.min.js"></script>

        <script>
// More info https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({
  history: true,
  // 是否在右下角展示控制条
  controls: true,
  // 是否显示演示的进度条
  progress: true,
  // 是否显示当前幻灯片的页数编号，也可以使用代码 “slideNumber: 'c/t'” ，表示当前页/总页数。
  slideNumber: false,
  // 是否将每个幻灯片改变加入到浏览器的历史记录中去
  history: false,
  // 是否启用键盘快捷键来导航
  keyboard: true,
  // 是否启用幻灯片的概览模式，可使用 "Esc" 或 "o" 键来切换概览模式
  overview: true,
  // 是否将幻灯片垂直居中
  center: true,
  // 是否在触屏设备上启用触摸滑动切换
  touch: true,
  // 是否循环演示
  loop: false,
  // 是否将演示的方向变成 RTL，即从右往左
  rtl: false,
  // 是否每次演示的时候，随机幻灯片的顺序
  shuffle: false,
  // 全局开启和关闭碎片。
  fragments: true,
  // 标识演示文稿是否在嵌入模式中运行，即包含在屏幕的有限部分中的
  embedded: false,
  // 标识当问号键被点击的时候是否应该显示一个帮助的覆盖层
  help: true,
  // 标识演讲者备注标志是否让所有观看者可见
  showNotes: false,
  // 两个幻灯片之间自动切换的时间间隔（毫秒）
  // 当设置成 0 的时候则禁止自动切换
  // 该值可以被幻灯片上的 “data-autoslide” 属性覆盖
  autoSlide: 0,
  // 当遇到用户输入的时候停止自动切换
  autoSlideStoppable: true,
  // 当自动滑动时，使用此方法进行导航。
  autoSlideMethod: Reveal.navigateNext,
  // 是否启用通过鼠标滚轮来导航幻灯片
  mouseWheel: false,
  // 是否在移动设备上隐藏地址栏
  hideAddressBar: true,
  // 是否在一个弹出的 iframe 中打开幻灯片中的链接
  previewLinks: false,
  // 切换过渡效果
  transition: 'zoom', // none/fade/slide/convex/concave/zoom
  // 过渡速度
  transitionSpeed: 'default', // default/fast/slow
  // 全屏幻灯片背景的过渡效果
  backgroundTransition: 'slide', // none/fade/slide/convex/concave/zoom
  // 加载除当前可见的幻灯片之外的幻灯片数量
  viewDistance: 3,
  // 视差背景图片
  parallaxBackgroundImage: 'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-2.jpg',
  // e.g. 'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'
  // 视差背景尺寸
  parallaxBackgroundSize: '', // CSS syntax, e.g. "2100px 900px"
  // 移动视差背景（水平和垂直）滑动变化的数量, 例如 100
  // - 除了指定自动计算
  // - 设置为 0 时，禁止沿轴运动
  parallaxBackgroundHorizontal: null,
  parallaxBackgroundVertical: null,
  width: 1920,
	height: 1200,

	// Factor of the display size that should remain empty around the content
	margin: 0,

	// Bounds for smallest/largest possible scale to apply to content
	minScale: 0.9,
	maxScale: 3,
  // More info https://github.com/hakimel/reveal.js#dependencies
  math: {
		mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
		config: 'TeX-AMS-MML_HTMLorMML'  // See http://docs.mathjax.org/en/latest/config-files.html

	},
	//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML
  dependencies: [
    { src: 'https://cdn.bootcss.com/reveal.js/3.4.1/plugin/markdown/marked.js' },
    { src: 'https://cdn.bootcss.com/reveal.js/3.4.1/plugin/math/math.js', async: true },
    { src: 'https://cdn.bootcss.com/reveal.js/3.4.1/plugin/markdown/markdown.min.js' },
    { src: 'https://cdn.bootcss.com/reveal.js/3.4.1/plugin/notes/notes.min.js', async: true },
    { src: 'https://cdn.bootcss.com/reveal.js/3.4.1/plugin/highlight/highlight.min.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
  ]
});
        </script>
    </body>
</html>
