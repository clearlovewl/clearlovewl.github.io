<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content=",,">










<meta name="description" content="Deep Bilinear Pooling for BlindImage Quality Assessment">
<meta name="keywords" content="pytorch,IQA">
<meta property="og:type" content="website">
<meta property="og:title" content="Deep Bilinear Pooling for BlindImage Quality Assessment">
<meta property="og:url" content="http://yoursite.com/DBCNN.html">
<meta property="og:site_name" content="wl-uestc">
<meta property="og:description" content="Deep Bilinear Pooling for BlindImage Quality Assessment">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://yoursite.com/Artisticstyle/1.png">
<meta property="og:image" content="http://yoursite.com/Artisticstyle/1.png">
<meta property="og:image" content="http://yoursite.com/Artisticstyle/2.png">
<meta property="og:updated_time" content="2019-03-12T08:22:15.763Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Deep Bilinear Pooling for BlindImage Quality Assessment">
<meta name="twitter:description" content="Deep Bilinear Pooling for BlindImage Quality Assessment">
<meta name="twitter:image" content="http://yoursite.com/Artisticstyle/1.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/DBCNN.html">





  <title>Deep Bilinear Pooling for BlindImage Quality Assessment | wl-uestc</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">wl-uestc</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    
    
    
    <div class="post-block page">
      <header class="post-header">

	<h1 class="post-title" itemprop="name headline">Deep Bilinear Pooling for BlindImage Quality Assessment</h1>


	<div class="post-meta">
		<div class="post-description">Deep Bilinear Pooling for BlindImage Quality Assessment</div>
	</div>


</header>

      
      
      
      <div class="post-body">
        
        
          <p><img src="/Artisticstyle/1.png" alt="1"><br><!-- .element style="border: 0; background: None; box-shadow: None" height="800px"   --></p>
<p>we propose  a deep bilinear model for image quality assessment that handles both synthetic and authentic distortions .</p>
<p>for synthetic distortions ,we  pre-train  a  CNN  to classify  image  distortion  type  and  level，where we enjoy large scale training data .</p>
<p>for authentic distortions, we adopt a pre trained CNN for image classification.</p>
<p>each of which specializes in one distortion  scenario</p>
<p>the features from the two CNNs are pooled bilinearly into a unified representation for final quality prediction .</p>
<hr>
<h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>NOWADAYS,digital images are captured via various mobile cameras ,compressed by conventional and advanced techniques ,transmitted through diverse communication channels,and stored on different devices.each stage in the image processing pipeline could introduce unexpected distortions,leading to perceptual quality degradation.therefore,image quality assessment is of great importance to monitoring  the quality of images and ensuring the reliability of image processing systems.it is essential to design accurate and efficient computational models topush IQA from laboratory research to real-world applications. Among all computational models ,we are interested in no reference or blind IQA methods ,because the reference informations is often unavailable in many practical applications .</p>
<p>​    previous knowledge driven BIQA models typically adopt low level features either hand crafted or learned to characterize the level of deviations from statistical regularities of natural scenes .until recently,there has been limited effort towards end to end optimized BIQA using deep convolutional neural networks , primarity due to the lack of sufficient groud truths such as the mean opinion scores for training .a strainghtforward approach is to fine tune a cnn pretrained ON Imagenet for quality prediction. The resulting model performs reasonlably on the LIVE Challenge Database with authentic distortions. but does not stand out on the live and tid2013 database with systhetic distortion. another commons strategy is patch based training, where the patch level groud truths are either inherited from image level annotations or approximated by full reference IQA models .this strategy is very effective at learning CNN based models for synthetic distortions,but fails to handle authentic distorations due to the non-homogeneity of distortions and the absence of reference images . Other methods,take advantage of synthetic degradation processes to find reasonable initializations for CNN based models ,but cannot be applied to authentic distortions either.</p>
<p>​    in this work ,we aim for an end to end solutions to BIQA that handles both synthetic and authentic distortions . we first learn two feature sets for the two distortion scenarios separately .For synthetic distortions .inspired by previous studies ,we construct a large scale pre trained data based on the waterloo exploration database and the pascal voc database ,where the image are synthesized with nine distortion types and two to five distorion levels .we take advantage of known distortion type and level information in the dataset and pretrained a CNN through a multi class classification task. for authentic distortions ,it is difficult to simulate the degradation process due to their complexities.therefore,we opt for another CNN pretrained on Imagenet .we model synthentic and authentic distortions as two-factor variations,and pool the two feature sets bilinearly into a unified representation for final quality prediction. the resulting DBCNN is…….. .</p>
<hr>
<h2 id="RELATED-WORK"><a href="#RELATED-WORK" class="headerlink" title="RELATED WORK"></a>RELATED WORK</h2><p>in this section,we provide a review of recent CNN based BIQA models.for a more detailed tratment of BIQA ,we refer the interested to .tang pretrained a deep belief network with a radial basis function and fine tuned it to predict image quality .Bianco investigated various design choices for CNN based BIQA . they first adopted off the shelf CNN features to learn a quality evaluator using support vector regression.kang trained a CNN using a large number of  spatially normalized image patches .later ,they estimate image quality and distortion typesimultaneously via a multi task cnn.patch based training maybe problematic because due to the high nonstationarity of local image content and the intricate interactions between content and distortion ,local image quality is not always consistent with globle image quality .taking this problem into consideration,bosse trained cnn models using two strategies :direct average of features from multiple patches and weighted average of patch quality scores according to their relative importance .kim pretrained a cnn model using numerous patches with proxy quality scores provided by a full-reference IQA model and summarized the patch level features using the mean and standard deviation stastics for fine tuning .a</p>
<p>a closely related work to ours is meon.starting fromthe pretrained early layers and the outputs of thedistortion type .compared with meon,the proposed DB CNN takes a step further by considering notonly the distortion type but also the distortion level information,which results in better quality-aware initializations.</p>
<p>in summary, the aforementioned methods partially address the training data shortage problem in the synthetic distortion scenario, but it is difficult to extend them to the authentic distortion scenario .</p>
<p>前言万语一句话，他这个网络对自然场景失真有好处。其他人的没有考虑。</p>
<p>—</p>
<p>—</p>
<hr>
<h2 id="DBCNN-for-BIQA"><a href="#DBCNN-for-BIQA" class="headerlink" title="DBCNN for BIQA"></a>DBCNN for BIQA</h2><ol>
<li></li>
<li>here we introduce an artificial system based on a deep neural network that creates artistic images providing a neural algorithm for the creation of artistic images</li>
<li>our work offers a path forward to an algorithmic under-standing of how humans create and perceive artistic imagery</li>
</ol>
<p>—</p>
<p>—</p>
<h2 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h2><ol>
<li><p>a layer with <script type="math/tex">N _ { l }</script> distinct filters has <script type="math/tex">N _ { l }</script> feature maps each of size <script type="math/tex">M _ { l }</script>，where <script type="math/tex">M _ { l }</script> is the height times the width of the feature map.</p>
</li>
<li><p>so the responses in a layer l can be stored in a matrix <script type="math/tex">F ^ { l } \in \mathcal { R } ^ { N _ { l } \times M _ { l } }​</script>  where <script type="math/tex">F _ { i j } ^ { l }​</script> is the activation of the ith filter at position j in layer l</p>
</li>
<li><p>so let <script type="math/tex">\vec { p }</script> and <script type="math/tex">\vec {x}</script> be the original image and the image that is generated and <script type="math/tex">P ^ { l }</script> and <script type="math/tex">F ^ { l }</script> their respective feature representation in layer l.  we then define the squared-error loss between the two feature representations<br><code>$$
\mathcal { L } _ { \text {content} } ( \vec { p } , \vec { x } , l ) = \frac { 1 } { 2 } \sum _ { i , j } \left( F _ { i j } ^ { l } - P _ { i j } ^ { l } \right) ^ { 2 }
$$</code></p>
</li>
</ol>
<p>—</p>
<p>4  these feature correlations are given by the gram matrix <script type="math/tex">G ^ { l } \in \mathcal { R } ^ { N _ { l } \times N _ { l } }​</script>  where  <script type="math/tex">G _ { i j } ^ { l }​</script> is the inner product between the feature map i and j in layer l  :<br>`$$<br>G _ { i j } ^ { l } = \sum _ { k } F _ { i k } ^ { l } F _ { j k } ^ { l }</p>
<script type="math/tex; mode=display">`

5  so let $$\vec { a }$$ and $$\vec { x }$$ be the original image and the image that is generated and $$A ^ { l }$$  and   $$G ^ { l }$$  their respective style representations in layer l.  the contribution of that layer to the total loss is then  



`</script><p>   E _ { l } = \frac { 1 } { 4 N _ { l } ^ { 2 } M _ { l } ^ { 2 } } \sum _ { i , j } \left( G _ { i j } ^ { l } - A _ { i j } ^ { l } \right) ^ { 2 }</p>
<script type="math/tex; mode=display">`



   and the total loss is

`</script><pre><code>\mathcal { L } _ { s t y l e } ( \vec { a } , \vec { x } ) = \sum _ { l = 0 } ^ { L } w _ { l } E _ { l }
</code></pre><script type="math/tex; mode=display">`

--

6  so let $\vec { p }$  be the photograph and $\vec { a }$ be the artwork. the loss function we minimise is 

`</script><p>\mathcal { L } _ { \text {total} } ( \vec { p } , \vec { a } , \vec { x } ) = \alpha \mathcal { L } _ { \text {content} } ( \vec { p } , \vec { x } ) + \beta \mathcal { L } _ { \text {style} } ( \vec { a } , \vec { x } )</p>
<p>$$`</p>
<p>   where α and β are the weighting factors for content and style reconstruction respectively</p>
<p>—<br><img src="/Artisticstyle/1.png" alt="1"><br><!-- .element style="border: 0; background: None; box-shadow: None" height="800px"   --></p>
<p>—</p>
<h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><p>fig 2 shows results for different relative weightings of the content and style reconstruction loss (along the columns) and for matching the style representations only on layer ‘conv11’ (a), ‘conv11’ and ‘conv21’ (b), ‘conv11’, ‘conv21’ and ‘conv31’ (c),‘conv11’, ‘conv21’, ‘conv31’ and ‘conv41’ (d), ‘conv11’, ‘conv21’, ‘conv31’, ‘conv41’and ‘conv51’ (e). </p>
<p>—<br><img src="/Artisticstyle/2.png" alt="2"><br><!-- .element style="border: 0; background: None; box-shadow: None" height="900px"   --></p>
<p>—</p>
<blockquote>
<p><a href="https://clearlovewl.github.io/2019/02/26/Artisticstyle/slide.html" target="_blank" rel="noopener">ppt</a><br><a href="http://localhost:4000/2019/02/26/Artisticstyle/slide.html" target="_blank" rel="noopener">ppt</a></p>
</blockquote>

        
      </div>
      
      
      
    </div>
    
    
    
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">wang lei</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">15</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">13</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#INTRODUCTION"><span class="nav-number">1.</span> <span class="nav-text">INTRODUCTION</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RELATED-WORK"><span class="nav-number">2.</span> <span class="nav-text">RELATED WORK</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DBCNN-for-BIQA"><span class="nav-number">3.</span> <span class="nav-text">DBCNN for BIQA</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Methods"><span class="nav-number">4.</span> <span class="nav-text">Methods</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Results"><span class="nav-number">5.</span> <span class="nav-text">Results</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">wang lei</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
